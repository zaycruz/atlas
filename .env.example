# Example environment configuration for Atlas
# Copy this file to `.env` and adjust as needed for your local setup.

# Default chat model served by your local Ollama instance
ATLAS_CHAT_MODEL=gpt-oss:latest

# Embedding model name exposed by Ollama for semantic search
ATLAS_EMBED_MODEL=e5-large

# Optional: custom path for long-term memory storage
# ATLAS_MEMORY_DIR=~/.atlas/memory

# Optional: override summarizer/harvest models if you have larger builds available
# ATLAS_SUMMARY_MODEL=phi3:latest
# ATLAS_MEMORY_MODEL=llama3:8b
